# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mgMC8bLZ0puGrCRvjLo9V3HgvLpB9DFg

# AI training

This will become the main AI training method/function

### Data Preprocessing
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
import torch.nn.functional as F
from torchvision import transforms
from torch.utils.data import random_split
from torchvision.transforms import ToTensor
from torchvision.datasets import ImageFolder
from torch.utils.data import Dataset, DataLoader
from torchvision.utils import make_grid
import matplotlib.pyplot as plt
import torch.nn as nn
import os
new_dir_path = 'saved_model'

os.makedirs(new_dir_path, exist_ok=True)

transform = transforms.Compose([
    transforms.Resize((128, 128)), 
    # transforms.RandomHorizontalFlip(),
    # transforms.RandomVerticalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((.5, .5, .5), (.5, .5, .5))
    
])

total_ds = ImageFolder('/insert link/', transform=transform)

from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, Subset

TEST_SIZE = 0.2
BATCH_SIZE = 64
SEED = 42

# generate indices: instead of the actual data we pass in integers instead
train_indices, test_indices, _, _ = train_test_split(
    range(len(total_ds)),
    total_ds.targets,
    # stratify=total_ds.targets,
    test_size=TEST_SIZE,
    random_state=SEED
)


# generate subset based on indices
train_ds = Subset(total_ds, train_indices)
eval_ds = Subset(total_ds, test_indices)

batch_size=64
train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)
eval_dl = DataLoader(eval_ds, batch_size, num_workers=2, pin_memory=True)

"""Visualisation of data"""

batch_size=32
train_dl2 = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)
for images, _ in train_dl2:
    print('images.shape:', images.shape)
    plt.figure(figsize=(16,8))
    plt.axis('off')
    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))
    break

classes = total_ds.classes

"""### Model construction and Training"""

# Define relevant variables for the ML task
batch_size = 64
num_classes = len(classes)
learning_rate = 0.00001
num_epochs = 100
device = 'cuda'
# device = 'cpu'

# Creating a CNN class
class ConvNeuralNet(nn.Module):
	#  Determine what layers and their order in CNN object 
    def __init__(self, num_classes):
        super(ConvNeuralNet, self).__init__()
        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)
        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)
        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)
        self.batch_norm1 = nn.BatchNorm2d(32)

        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)
        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)
        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)
        self.batch_norm2 = nn.BatchNorm2d(64)
        
        self.fc1 = nn.Linear(53824, 128)
        self.batch_norm3 = nn.BatchNorm1d(128)

        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(128, num_classes)

        self.dropout = nn.Dropout(0.4)
    # Progresses data across layers    
    def forward(self, x):
        out = self.conv_layer1(x)
        out = self.conv_layer2(out)
        out = self.max_pool1(out)
        out = self.batch_norm1(out)
        out = self.dropout(out)

        out = self.conv_layer3(out)
        out = self.conv_layer4(out)
        out = self.max_pool2(out)
        out = self.batch_norm2(out)
        out = self.dropout(out)
               
        out = out.reshape(out.size(0), -1)
        
        out = self.fc1(out)
        out = self.batch_norm3(out)
        out = self.relu1(out)
        out = self.dropout(out)

        out = self.fc2(out)
        return out

model = ConvNeuralNet(num_classes)
model = model.to(device)
# Set Loss function with criterion
criterion = nn.CrossEntropyLoss()

# Set optimizer with optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  

total_step = len(train_dl)

# We use the pre-defined number of epochs to determine how many iterations to train the network on
for epoch in range(num_epochs):
	#Load in the data in batches using the train_loader object
    for i, (images, labels) in enumerate(train_dl):  
        # Move tensors to the configured device
        images = images.to(device)
        labels = labels.to(device)
        
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))

torch.save(model.state_dict(), '/saved_model')

"""### Evaluation"""

model = ConvNeuralNet(num_classes)
model.load_state_dict(torch.load('/saved_model'))
model = model.to(device)

with torch.no_grad():
    correct = 0
    total = 0
    for pred_images, pred_labels in eval_dl:
        pred_images = pred_images.to(device)
        pred_labels = pred_labels.to(device)
        pred_outputs = model(pred_images)
        _, pred_predicted = torch.max(pred_outputs.data, 1)
        total += pred_labels.size(0)
        correct += (pred_predicted == pred_labels).sum().item()
    
    print('Accuracy of the network on the {} train images: {} %'.format(len(eval_dl.dataset), 100 * correct / total))

"""### Application mode

**Note:**Make a folder within a folder and add the image to test in that. Change the path of `app_image` to point to the outer folder.
"""

transform = transforms.Compose([
    transforms.Resize((128, 128)), 
    transforms.ToTensor(),
    transforms.Normalize((.5, .5, .5), (.5, .5, .5))
    ])
app_image = ImageFolder('/insert link/', transform=transform)
app_dl = DataLoader(app_image, batch_size, shuffle=True, num_workers=2, pin_memory=True)

model = ConvNeuralNet(num_classes)
model.load_state_dict(torch.load('/saved_model'))
model = model.to(device)

with torch.no_grad():
    model.eval()
    correct = 0
    total = 0
    for images, labels in app_dl:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)

print('The predicted class is:  ' , classes[predicted.item()])

"""### Evaluation"""

from sklearn.metrics import precision_recall_fscore_support as score
from sklearn.metrics import classification_report

eval_labels = pred_labels.detach().cpu()
eval_predictions = pred_predicted.detach().cpu()

print(classification_report(eval_labels, eval_predictions))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from matplotlib.pyplot import figure

figure(figsize=(80, 60), dpi=80)
cm = confusion_matrix(eval_labels, eval_predictions)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=['no mask', 'cloth', 'surgical', 'n95'])
disp.plot()

plt.show()

cm

