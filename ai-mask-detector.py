# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N7RzZrXc5_GzeWdiyN7Tmj71cI65CcMh
"""

print("hello world")

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img = mpimg.imread('/content/drive/MyDrive/dataset/1.no_mask')
imgplot = plt.imshow(img)
plt.show()

from google.colab import drive
drive.mount('/content/drive')

"""# New Section"""

# load some images

import cv2
import glob
import matplotlib.pyplot as plt
import matplotlib.image as mpimg


imdir = '/content/drive/MyDrive/dataset/1.no_mask/'
ext = ['png', 'jpg', 'jpeg', 'gif']    # Add image formats here

files = []
[files.extend(glob.glob(imdir + '*.' + e)) for e in ext]

images = [cv2.imread(file) for file in files]

imgplot = plt.imshow(images[0])
print(images[0])
plt.show()


# show pixel values
plt.hist(images[0].ravel(), bins=50, density=True)
plt.xlabel("pixel values")
plt.ylabel("relative frequency")
plt.title("distribution of pixels")



"""# AI training

This will become the main AI training method/function

"""

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image

#img = mpimg.imread('/content/images/thrawn.jpg')
img = Image.open('/content/images/thrawn.jpg')
imgplot = plt.imshow(img)
plt.show()

"""import torch
import torchvision.transforms as transforms

#testTensor = torch.empty(1)
#print(testTensor)

#imgplot = plt.imshow(img)
#plt.show()

# Uttility functions
toTensor = transforms.ToTensor()
toImage = transforms.ToPILImage()
scaleIt = transforms.Compose([transforms.Resize(48)])
print("The sise of the non rescaled image tensor is:",toTensor(img).size())
print("The sise of the non rescaled image flattened tensor is:",torch.flatten(toTensor(img)).size())

#Creating a matrix of weights and resizing the image
tensorOfOnes=torch.ones(9216,9216)
imgResized = scaleIt(img)
print(img)
print(imgResized) 



testTensor2= toTensor(imgResized)
testWeights=tensorOfOnes*0.5
#matrixOfWeights=

#flattenedTensor = torch.flatten(testTensor2[0])

flattenedTensor = torch.flatten(testTensor2)
resultJustForFun=flattenedTensor
result=torch.mv(testWeights,flattenedTensor)
print(flattenedTensor)
print(resultJustForFun)
print(result)



resultReshaped=resultJustForFun.reshape(3, 48, 64)
resultingImage=toImage(resultReshaped)

imgplot = plt.imshow(imgResized)
plt.show()
imgplot = plt.imshow(resultingImage)
plt.show()



print("****************")
print("Original")
print(testTensor2)
print("Original size")
print(testTensor2.size())
print("****************")
print(testWeights.size())
print(flattenedTensor.size())
print(result.size())
print(result)
print("****************")
print("After")
print(resultReshaped)

Image preprocessing method/fucntion:
"""

import torch
import torchvision.transforms as transforms

#Rescales an dataset of images (in an array) to the desired size=(widt, height), and returns a list of PIL images
def preprocess(data, size):
    toTensor = transforms.ToTensor()
    scaleIt = transforms.Compose([transforms.Resize(size)])
    toImage = transforms.ToPILImage()


    outpurImages = [] 
    for image in data:
        img=toImage(image)
        tensor=toTensor(img)
        rescaledTensor= scaleIt(tensor)
        rescaledTensor= scaleIt(rescaledTensor)
        rescaledImage=toImage(rescaledTensor)
        outpurImages.append(rescaledImage)
    return outpurImages