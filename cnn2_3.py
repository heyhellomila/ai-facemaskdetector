# -*- coding: utf-8 -*-
"""cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pAicnuXZaUELSg0IZEckX_FzNEzyCoFY
"""

import torch
torch.cuda.is_available()

# imports
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch

#from google.colab import drive
#drive.mount('/content/drive')

#Chosing which device to run the training on. Uncomment the one you need.
#device = 'cpu'
device=torch.device("cuda")

#The flag for checking/saving model per epoch or per iteration (1 epoch ~ 38 iterations)
save_per_iteration= False

#The flag to switch on save based on accuracy or save based on loss (for iteration_based save only)
save_on_loss = False

#The flag to switch on save based on accuracy AND based on loss
save_on_accuracy_and_loss = True

import gc
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'

gc.collect()

# Clearing Cuda cache
torch.cuda.empty_cache()

def get_data():
    #data_dir = '/content/drive/MyDrive/classified'
    data_dir = 'C:/Users/bl/Documents/CNNcomp472/classified'
    
    
    transform = transforms.Compose([transforms.ToTensor(),
                                    transforms.Resize((256,256)),
                                    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))]) 

    
    original_set = datasets.ImageFolder(root=data_dir, transform=transform)  # dataset

    print(original_set.classes)
    n = len(original_set)  # total number of examples
    n_test= int(0.25*n)# take ~25% for test
    for x in range(0, 9): # rounding it to be divisible by 4
      n_test+=1
      if n_test % 4 == 0: 
        break 

    # test_set = torch.utils.data.Subset(original_set, range(n_test))  # take first 25%
    # train_set = torch.utils.data.Subset(original_set, range(n_test, n))  # take the rest


    train_set, test_set = torch.utils.data.random_split(original_set, [n-n_test, n_test])

    train = DataLoader(train_set, batch_size=32, shuffle=True)
    #test = DataLoader(test_set, batch_size=int(len(test_set)/4), shuffle=False)
    test = DataLoader(test_set, batch_size=1000, shuffle=False)

    print(len(train_set))
    print(len(test_set))
    print(n)
    

    return train, test, train_set, test_set, original_set

train, test, train_set, test_set, original_set = get_data()

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        
        self.conv_layer1 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3,stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(p=0.1),
        )

        self.conv_layer2 = nn.Sequential(
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(p=0.1),
        )

                
        self.conv_layer3 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3,stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(p=0.1),
        )
        
        self.fc_layer1 = nn.Sequential(
            nn.Linear(32 * 32 * 128, 1000),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.1),
        )

        self.fc_layer2 = nn.Sequential(
            nn.Linear(1000, 1000),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.1),
        )

        self.fc_layerFinal = nn.Sequential(
            nn.Linear(1000, 4),
        )
        
    def forward(self, x):
        # conv layers
        x = self.conv_layer1(x)
        x = self.conv_layer2(x)
        x = self.conv_layer3(x)
        # flatten
        x = x.view(x.size(0), -1)
        # fc layers
        x = self.fc_layer1(x)
        x = self.fc_layer2(x)
        x = self.fc_layerFinal(x)
        return x

num_epochs = 2
num_classes = 4
learning_rate = 0.001

# Setting up the model
model = CNN()
model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
total_step = len(train)
loss_list = []
acc_list = []
iterations=[]
iterations_improved=[]#graph
epoch_iterations=[]
accuracyListPerEpoch=[] # Keeps track of the accuracies for each epoch
accuracyListPerEpoch_improved=[]
acc_list_improved = []
loss_list_improved =[9999999]

# The training. Only saving the model, after each epoch/iteration (depending on flag) , if the accuracy improves. Printing accuracies at each epoch.
n=0 # For the graph
n2=0 # For the epoch graph
n3=0 # For the graph
for epoch in range(num_epochs):

    # If save_per_iteration flag is False it will save/load training per epoch
    if save_per_iteration == False:
        # Checking if the model exist in the folder. If it doesn't, it will not load a model from it
        if os.path.exists('C:/Users/bl/Desktop/cnnModelSaves/model.pth'):
            model.load_state_dict(torch.load('C:/Users/bl/Desktop/cnnModelSaves/model.pth'))
            model = model.to(device)

    for i, (images, labels) in enumerate(train):

        # If save_per_iteration flag is True it will save/load training per iteration
        if save_per_iteration == True:
            # Checking if the model exist in the folder. If it doesn't, it will not load a model from it
            if os.path.exists('C:/Users/bl/Desktop/cnnModelSaves/model.pth'):
                model.load_state_dict(torch.load('C:/Users/bl/Desktop/cnnModelSaves/model.pth'))
                model = model.to(device)

        # Move them to device (cuda or cpu)
        images = images.to(device)
        labels = labels.to(device)
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss_list.append(loss.item())
        # Backprop and optimisation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        # Train accuracy
        total = labels.size(0)
        _, predicted = torch.max(outputs.data, 1)
        correct = (predicted == labels).sum().item()
        acc_list.append(correct / total)

        #print(i)

        # If save_per_iteration flag is True it will save/load training per iteration
        if save_per_iteration == True:

            if (save_on_loss == False) and (save_on_accuracy_and_loss == False):
                # Checking if the accuracy has improved this iteration. If so it will save that model,
                # otherwise it will just reload the previous model and continue from there.
                if (((i <= 0) and (epoch<=0)) or (acc_list[i] >= acc_list_improved[-1])):
                    print("saving iteration")
                    print(acc_list[i])
                    if acc_list_improved:
                        print(acc_list_improved[-1])
                    print()
                    torch.save(model.state_dict(), 'C:/Users/bl/Desktop/cnnModelSaves/model.pth')

                    #For graph
                    iterations_improved.append(n3)
                    n3+=1
                    acc_list_improved.append(acc_list[i])

            if save_on_loss == True:
                #Checking if loss has reduced
                if (((i <= 0) and (epoch<=0)) or (loss_list[i] <= loss_list_improved[-1])):
                    print("saving iteration")
                    print(loss_list[i])
                    if loss_list_improved:
                        print(loss_list_improved[-1])
                    print()
                    torch.save(model.state_dict(), 'C:/Users/bl/Desktop/cnnModelSaves/model.pth')

                    #For graph
                    iterations_improved.append(n3)
                    n3+=1
                    loss_list_improved.append(loss_list[i])

            if save_on_accuracy_and_loss == True:
                # Checking if the accuracy has improved this iteration, if not it checks if loss reduced. The saves if any of those cases.
                if (((i <= 0) and (epoch <= 0)) or (acc_list[i] >= acc_list_improved[-1]) or (loss_list[i] <= loss_list_improved[-1])):
                    print("saving iteration")
                    print(acc_list[i])
                    if acc_list_improved:
                        print(acc_list_improved[-1])
                    print()
                    torch.save(model.state_dict(), 'C:/Users/bl/Desktop/cnnModelSaves/model.pth')

                    if loss_list_improved:
                        if (loss_list[i] <= loss_list_improved[-1]):
                            loss_list_improved.append(loss_list[i])
                    else:
                        loss_list_improved.append(loss_list[i])

                    # For graph
                    iterations_improved.append(n3)
                    n3 += 1
                    acc_list_improved.append(acc_list[i])


        #For the graph
        iterations.append(n)
        n+=1


    #Claculating the accuracy of this epoch and adding it to the array
    accuracy= (correct / total) * 100
    accuracyListPerEpoch.append(accuracy)


    # If save_per_iteration flag is False it will save/load training per epoch
    if save_per_iteration == False:
        if save_on_accuracy_and_loss == False:
            # Checking if the accuracy has improved this epoch. If so it will save that model,
            # otherwise it will just reload the previous  model and continue from there.
            if ((epoch <= 0) or (accuracyListPerEpoch[epoch] >= accuracyListPerEpoch_improved[-1])):
                print("saving epoch")
                print()
                torch.save(model.state_dict(), 'C:/Users/bl/Desktop/cnnModelSaves/model.pth')

                # For the graph
                epoch_iterations.append(n)
                n2 += 1
                accuracyListPerEpoch_improved.append(accuracyListPerEpoch[epoch])

        if save_on_accuracy_and_loss == True:
            if ((epoch <= 0) or (accuracyListPerEpoch[epoch] >= accuracyListPerEpoch_improved[-1]) or (loss_list[i] <= loss_list_improved[-1])):
                print("saving epoch")
                print()
                torch.save(model.state_dict(), 'C:/Users/bl/Desktop/cnnModelSaves/model.pth')

                if loss_list_improved:
                    if (loss_list[i] <= loss_list_improved[-1]):
                        loss_list_improved.append(loss_list[i])
                else:
                    loss_list_improved.append(loss_list[i])

                # For the graph
                epoch_iterations.append(n)
                n2 += 1
                accuracyListPerEpoch_improved.append(accuracyListPerEpoch[epoch])
    print()
    print("____________")
    print("The epoch is:")
    print(epoch)
    print("Every accuracy")
    print(accuracyListPerEpoch)
    print("Saved accuracy")
    print(accuracyListPerEpoch_improved)
    print("**************")
    print()

    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'
        # print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'
        .format(epoch + 1, num_epochs, loss.item(),
        accuracy))


######################################
# Plotting
# The code for the plotting is taken from https://www.cs.toronto.edu/~lczhang/360/lec/w02/training.html
plt.plot(iterations, loss_list)
plt.title("Training Curve (batch_size={}, lr={})".format(len(train_set), learning_rate))
plt.xlabel("Iterations")
plt.ylabel("Loss")
plt.show()
plt.plot(iterations, acc_list)
plt.title("Training Curve (batch_size={}, lr={})".format(len(train_set), learning_rate))
plt.xlabel("Iterations")
plt.ylabel("Training Accuracy")
plt.show()

if save_per_iteration == True:
    plt.plot(iterations_improved, acc_list_improved)
    plt.title("Training Curve per iteration improved only (batch_size={}, lr={})".format(len(train_set), learning_rate))
    plt.xlabel("Iterations")
    plt.ylabel("Training Accuracy")
    plt.show()

if save_per_iteration == False:
    plt.plot(epoch_iterations, accuracyListPerEpoch_improved)
    plt.title("Training Curve per epoch improved only (batch_size={}, lr={})".format(len(train_set), learning_rate))
    plt.xlabel("Iterations")
    plt.ylabel("Training Accuracy")
    plt.show()
######################################




# Saving the trained model and emptying the GPU memory
torch.save(model.state_dict(), 'C:/Users/bl/Desktop/cnnModelSaves/model.pth')
#del model
torch.cuda.empty_cache()



#Loading the model before testing
device = 'cpu'
model = CNN()

#if os.path.exists('C:/Users/bl/Desktop/cnnModelSaves/model.pth'):
model.load_state_dict(torch.load('C:/Users/bl/Desktop/cnnModelSaves/model.pth'))
#else:
    #print("****The folder is empty*****")

model = model.to(device)

# Overall accuracy
with torch.no_grad():
    correct = 0
    total = 0
    for pred_images, pred_labels in test:
        pred_images = pred_images.to(device)
        pred_labels = pred_labels.to(device)
        pred_outputs = model(pred_images)
        _, pred_predicted = torch.max(pred_outputs.data, 1)
        total += pred_labels.size(0)
        correct += (pred_predicted == pred_labels).sum().item()
    
    print('Accuracy of the network on the {} train images: {} %'.format(len(test.dataset), (correct / total)*100 ))

# print tensors
classes = original_set.classes
with torch.no_grad():
    model.eval()
    correct = 0
    total = 0
    for images, labels in test:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        print("Predicted: ",predicted, len(predicted))
        print("Expected: ",labels,len(labels))
        total += labels.size(0)

from sklearn.metrics import precision_recall_fscore_support as score
from sklearn.metrics import classification_report

eval_labels = pred_labels.detach().cpu()
eval_predictions = pred_predicted.detach().cpu()


print(classification_report(eval_labels, eval_predictions))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from matplotlib.pyplot import figure

figure(figsize=(80, 60), dpi=80)
cm = confusion_matrix(eval_labels, eval_predictions)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=original_set.classes)
disp.plot()

plt.show()